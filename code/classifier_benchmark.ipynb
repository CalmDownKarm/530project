{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd95965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime                                                                                             \n",
    "                                                                           \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.reset_index().drop('index',axis=1).head()\n",
    "# df = test_data\n",
    "# df['h_tweets'] = df['home_tweets'].apply(len)\n",
    "# df['a_tweets'] = df['away_tweets'].apply(len)\n",
    "# h_tweets = df['h_tweets'].mean()\n",
    "# a_tweets = df['a_tweets'].mean()\n",
    "# print(h_tweets)\n",
    "# print(a_tweets)\n",
    "# len(test_data[test_data.HOME_TEAM_WINS==0])\n",
    "# train_data.reset_index().drop(['index','HOME_TEAM_ID','TEAM_ID_away','tweets'],axis=1).head()\n",
    "# for game in train_data['tweets']:\n",
    "#     print(game[0])\n",
    "# print(train_data['tweets'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fdb2d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet(\"data/train.pq\", engine='fastparquet')\n",
    "test_data = pd.read_parquet(\"data/test.pq\", engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bb32655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3228, 768)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_home_eb = np.load(\"data/train_home_embeddings.npy\")\n",
    "train_away_eb = np.load(\"data/train_away_embeddings.npy\")\n",
    "test_home_eb = np.load(\"data/test_home_embeddings.npy\")\n",
    "test_away_eb = np.load(\"data/test_away_embeddings.npy\")\n",
    "# print(train_home_eb[[0,1,2]])\n",
    "# print(train_away_eb[[0,1,2]])\n",
    "# print(test_home_eb[[0,1,2]])\n",
    "# print(test_away_eb[[0,1,2]])\n",
    "# print(np.allclose(train_home_eb, train_away_eb))\n",
    "# print(np.allclose(test_home_eb, test_away_eb))\n",
    "# print(np.allclose(train_home_eb[:807],test_home_eb))\n",
    "# print(np.allclose(train_away_eb[:807],test_away_eb))\n",
    "# train_home_eb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a592542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# trheb = train_home_eb.reshape(train_home_eb.shape[0], 1, -1)\n",
    "# traeb = train_away_eb.reshape(train_away_eb.shape[0], 1, -1)\n",
    "# TRAIN_X = np.concatenate(train_home_eb, train_away_eb)\n",
    "TRAIN_X = np.add(train_home_eb, train_away_eb)\n",
    "# TRAIN_X = TRAIN_X.reshape(TRAIN_X.shape[0], -1)\n",
    "TRAIN_Y = np.array(train_data['HOME_TEAM_WINS'])\n",
    "\n",
    "# test\n",
    "# tsheb = test_home_eb.reshape(test_home_eb.shape[0], 1, -1)\n",
    "# tsaeb = test_away_eb.reshape(test_away_eb.shape[0], 1, -1)\n",
    "# test_X = np.concatenate((tsheb,tsaeb), axis=1)\n",
    "TEST_X = np.add(test_home_eb, test_away_eb)\n",
    "# TEST_X = TEST_X.reshape(TEST_X.shape[0], -1)\n",
    "TEST_Y = np.array(test_data['HOME_TEAM_WINS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f130d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 1} 0.5814745482036144\n"
     ]
    }
   ],
   "source": [
    "param_test = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':range(1,2,3),\n",
    "#     'min_impurity_decrease':[6],\n",
    "    'class_weight':[None,'balanced']\n",
    "}\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_grid = param_test,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=5,\n",
    "    cv=5\n",
    ")\n",
    "gsearch.fit(TRAIN_X,TRAIN_Y)\n",
    "print(gsearch.best_params_, gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0dd4ac5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree:\n",
      " - train 0.515 (0.012)\n",
      " - test 0.515\n",
      " - f1 0.518\n"
     ]
    }
   ],
   "source": [
    "# classifiers = [\n",
    "#     DummyClassifier(strategy=\"uniform\", random_state=0),\n",
    "#     LogisticRegression(),\n",
    "#     KNeighborsClassifier(n_neighbors=10, weights='distance'),\n",
    "#     SVC(kernel='rbf'),\n",
    "#     DecisionTreeClassifier(),\n",
    "#     MLPClassifier(alpha=1, max_iter=1000),\n",
    "#     AdaBoostClassifier(),\n",
    "#     GradientBoostingClassifier(),\n",
    "#     GaussianNB(),\n",
    "#     Lasso()\n",
    "# ]\n",
    "\n",
    "def single_run(X_train, y_train, X_test, y_test):\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    return auc, clf\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "# name = clf.__class__.__name__\n",
    "best_auc = 0\n",
    "best_model = None\n",
    "aucs = []\n",
    "\n",
    "for train_index, test_index in skf.split(TRAIN_X, TRAIN_Y):\n",
    "    X_train, y_train = TRAIN_X[train_index], TRAIN_Y[train_index]\n",
    "    X_test, y_test = TRAIN_X[test_index], TRAIN_Y[test_index]\n",
    "\n",
    "    auc, curr_model = single_run(X_train, y_train, X_test, y_test)\n",
    "    aucs.append(auc)\n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        best_model = curr_model\n",
    "\n",
    "test_pred = best_model.predict(TEST_X)\n",
    "fpr, tpr, _ = metrics.roc_curve(TEST_Y, test_pred)\n",
    "test_auc = metrics.auc(fpr,tpr)\n",
    "f1_score = metrics.f1_score(TEST_Y, test_pred, average=\"weighted\")\n",
    "print(f\"GradientBoostingClassifier:\\n\"\n",
    "      f\" - train {round(np.mean(aucs),3)} ({round(np.std(aucs),3)})\\n\"\n",
    "      f\" - test {round(test_auc,3)}\\n\"\n",
    "      f\" - f1 {round(f1_score, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
